{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit.logger import Logger\n",
    "from toolkit.classes import DataFrameCreator\n",
    "from toolkit.pytorch_tools import CustomImageDataLoader\n",
    "from toolkit.pytorch_tools import NeuralNetwork\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import torch\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "logger = Logger(__name__).get_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataFrameCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m   INFO   \u001b[0m ] DataFrame created from data/raw/Validation as validation data\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] DataFrame created from data/raw/Train as train data\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] DataFrame created from data/raw/Test as test data\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Dataset loaded from data/raw folder\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Name :          train\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Type:           ('train',)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Columns:        ('path', 'filename', 'file', 'type', 'category', 'cat_idx')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Shape:          (300, 6)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Categories:     ('Non defective', 'Defective')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Path:           (PosixPath('data/raw/Train/Non defective'), PosixPath('data/raw/Train/Defective'))\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] File types:     ('jpg',)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Name :          validation\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Type:           ('validation',)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Columns:        ('path', 'filename', 'file', 'type', 'category', 'cat_idx')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Shape:          (62, 6)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Categories:     ('Non defective', 'Defective')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Path:           (PosixPath('data/raw/Validation/Non defective'), PosixPath('data/raw/Validation/Defective'))\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] File types:     ('jpg',)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Name :          test\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Type:           ('test',)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Columns:        ('path', 'filename', 'file', 'type', 'category', 'cat_idx')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Shape:          (22, 6)\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Categories:     ('Non defective', 'Defective')\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Path:           (PosixPath('data/raw/Test/Non defective'), PosixPath('data/raw/Test/Defective'))\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] File types:     ('jpg',)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data.load_dataset(\"./data/raw\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m   INFO   \u001b[0m ] CustomImageDataSet created\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Dataloaders created\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    ToPILImage(),\n",
    "    Resize((227, 227)),\n",
    "    CenterCrop((227, 227)),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "loader = CustomImageDataLoader(dataset=data, image_col=\"file\", label_col=\"cat_idx\", transform=transform)\n",
    "loader.create_dataloaders(batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m   INFO   \u001b[0m ] NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (13): Flatten(start_dim=1, end_dim=-1)\n",
      "    (14): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): Dropout(p=0.5, inplace=False)\n",
      "    (17): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (18): ReLU()\n",
      "    (19): Dropout(p=0.5, inplace=False)\n",
      "    (20): Linear(in_features=4096, out_features=1, bias=True)\n",
      "  )\n",
      "  (loss): BCELoss()\n",
      ")\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Setting up CUDA device\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] CUDA set up to device: NVIDIA GeForce MX150\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Model loaded to device: NVIDIA GeForce MX150\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "model.init_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ \u001b[32m   INFO   \u001b[0m ] Model training started\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Epoch:    0 Loss:  0.6951 Accuracy  0.4803  Validation loss:  0.6933   Validation accuracy:  0.4792\u001b[0m\n",
      "[ \u001b[32m   INFO   \u001b[0m ] Epoch:    1 Loss:  0.6930 Accuracy  0.5033  Validation loss:  0.6930   Validation accuracy:  0.4479\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "model.train(epochs=epochs, train_loader=loader[\"train\"], validation_loader=loader[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695133</td>\n",
       "      <td>0.480263</td>\n",
       "      <td>0.693343</td>\n",
       "      <td>0.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.693038</td>\n",
       "      <td>0.503289</td>\n",
       "      <td>0.692979</td>\n",
       "      <td>0.447917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  validation_loss  validation_acc\n",
       "0  0.695133  0.480263         0.693343        0.479167\n",
       "1  0.693038  0.503289         0.692979        0.447917"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.results.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f88e7f4e857ba56f1514bbda4896ee561c6e75047f3e04430fec61bb1f4b42e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
